{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import delta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Weili Fan\\\\Documents\\\\all\\\\rice\\\\courses\\\\2022 Fall\\\\ELEC 301\\\\project\\\\elec-301-speech-emotion-classification'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"./elec-301-speech-emotion-classification/data/data/\"\n",
    "path = \"./data/data/\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Weili Fan\\AppData\\Local\\Temp\\ipykernel_42716\\4200010588.py:6: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  samplerate, data = wavfile.read(file)\n",
      "C:\\Users\\Weili Fan\\AppData\\Local\\Temp\\ipykernel_42716\\4200010588.py:14: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  data_all = np.asarray(data_all)\n"
     ]
    }
   ],
   "source": [
    "# read train data\n",
    "data_all = []\n",
    "samplerate_all = []\n",
    "label = []\n",
    "for file in os.listdir():     \n",
    "    samplerate, data = wavfile.read(file)\n",
    "    samplerate_all.append(samplerate)\n",
    "    if (len(data.shape) > 1):\n",
    "        data_all.append(data[:,0])\n",
    "    else:\n",
    "        data_all.append(data)\n",
    "    label.append(str(file)[ : -7])\n",
    "\n",
    "data_all = np.asarray(data_all)\n",
    "label = np.asarray(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_all = []\n",
    "for i in range(len(data_all)):\n",
    "    features_mfcc = mfcc(data_all[i], samplerate_all[i], nfft=1200)\n",
    "    d_mfcc_feat = delta(features_mfcc, 2)\n",
    "    a_mfcc_feat = delta(d_mfcc_feat, 2)\n",
    "    feat = np.hstack([features_mfcc, d_mfcc_feat, a_mfcc_feat])\n",
    "    feat = feat.T\n",
    "    mfccs_processed = np.mean(feat,axis=1)\n",
    "    mfcc_all.append(mfccs_processed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1125, 39)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_all = np.asarray(mfcc_all)\n",
    "mfcc_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"../../test/test\"\n",
    "os.chdir(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Weili Fan\\AppData\\Local\\Temp\\ipykernel_42716\\3221594953.py:7: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  samplerate, data = wavfile.read(file)\n",
      "C:\\Users\\Weili Fan\\AppData\\Local\\Temp\\ipykernel_42716\\3221594953.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  test_data = np.asarray(test_data)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_data = []\n",
    "test_samplerate = []\n",
    "fileName = []\n",
    "NUM = []\n",
    "\n",
    "for file in os.listdir():     \n",
    "    samplerate, data = wavfile.read(file)\n",
    "    test_samplerate.append(samplerate)\n",
    "    if (len(data.shape) > 1):\n",
    "        test_data.append(data[:,0])\n",
    "    else:\n",
    "        test_data.append(data)\n",
    "    fileName.append(str(file[: -4]))\n",
    "    NUM.append(str(file[6: 9]))\n",
    "\n",
    "test_data = np.asarray(test_data)\n",
    "test_samplerate = np.asarray(test_samplerate)\n",
    "fileName = np.asarray(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315, 39)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_test = []\n",
    "for i in range(len(test_data)):\n",
    "    features_mfcc = mfcc(data_all[i], samplerate_all[i], nfft=1200)\n",
    "    d_mfcc_feat = delta(features_mfcc, 2)\n",
    "    a_mfcc_feat = delta(d_mfcc_feat, 2)\n",
    "    feat = np.hstack([features_mfcc, d_mfcc_feat, a_mfcc_feat])\n",
    "    feat = feat.T\n",
    "    mfccs_processed = np.mean(feat,axis=1)\n",
    "    mfcc_test.append(mfccs_processed)\n",
    "mfcc_test = np.asarray(mfcc_test)\n",
    "mfcc_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. PCA expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Weili Fan\\Documents\\all\\rice\\courses\\2022 Fall\\ELEC 301\\project\\mfcc svm 39.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Weili%20Fan/Documents/all/rice/courses/2022%20Fall/ELEC%20301/project/mfcc%20svm%2039.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Weili%20Fan/Documents/all/rice/courses/2022%20Fall/ELEC%20301/project/mfcc%20svm%2039.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Weili%20Fan/Documents/all/rice/courses/2022%20Fall/ELEC%20301/project/mfcc%20svm%2039.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pca\u001b[39m.\u001b[39;49mfit(mfcc_all)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Weili%20Fan/Documents/all/rice/courses/2022%20Fall/ELEC%20301/project/mfcc%20svm%2039.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m transformed \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(mfcc_all)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Weili%20Fan/Documents/all/rice/courses/2022%20Fall/ELEC%20301/project/mfcc%20svm%2039.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m transformed\u001b[39m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\Weili Fan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:408\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[39m    Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    401\u001b[0m check_scalar(\n\u001b[0;32m    402\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_oversamples,\n\u001b[0;32m    403\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_oversamples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    404\u001b[0m     min_val\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m    405\u001b[0m     target_type\u001b[39m=\u001b[39mnumbers\u001b[39m.\u001b[39mIntegral,\n\u001b[0;32m    406\u001b[0m )\n\u001b[1;32m--> 408\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    409\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Weili Fan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:456\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[1;32m--> 456\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    457\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    458\u001b[0m )\n\u001b[0;32m    460\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Weili Fan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\Weili Fan\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:893\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    888\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    889\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    890\u001b[0m     )\n\u001b[0;32m    892\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 893\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m     )\n\u001b[0;32m    898\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    899\u001b[0m     _assert_all_finite(\n\u001b[0;32m    900\u001b[0m         array,\n\u001b[0;32m    901\u001b[0m         input_name\u001b[39m=\u001b[39minput_name,\n\u001b[0;32m    902\u001b[0m         estimator_name\u001b[39m=\u001b[39mestimator_name,\n\u001b[0;32m    903\u001b[0m         allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    904\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. PCA expected <= 2."
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=2)\n",
    "# pca.fit(mfcc_all)\n",
    "# transformed = pca.transform(mfcc_all)\n",
    "# transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6817777777777778\n"
     ]
    }
   ],
   "source": [
    "lkf = svm.SVC(C = 10, kernel='rbf', gamma = 'scale')\n",
    "lkf.fit(mfcc_all,label)\n",
    "\n",
    "prediction = lkf.predict(mfcc_test)\n",
    "accuracy = accuracy_score(label, lkf.predict(mfcc_all))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'calm', 'angry', 'sad', 'happy', 'calm', 'calm',\n",
       "       'disgust', 'disgust', 'surprised', 'calm', 'surprised', 'calm',\n",
       "       'happy', 'sad', 'sad', 'angry', 'happy', 'disgust', 'sad',\n",
       "       'fearful', 'surprised', 'sad', 'angry', 'fearful', 'calm', 'sad',\n",
       "       'disgust', 'surprised', 'happy', 'happy', 'happy', 'calm', 'happy',\n",
       "       'disgust', 'disgust', 'fearful', 'surprised', 'angry', 'sad',\n",
       "       'fearful', 'calm', 'happy', 'angry', 'surprised', 'disgust',\n",
       "       'fearful', 'sad', 'surprised', 'sad', 'angry', 'sad', 'angry',\n",
       "       'calm', 'sad', 'fearful', 'sad', 'fearful', 'fearful', 'angry',\n",
       "       'sad', 'surprised', 'disgust', 'angry', 'angry', 'surprised',\n",
       "       'fearful', 'surprised', 'calm', 'fearful', 'surprised',\n",
       "       'surprised', 'happy', 'happy', 'fearful', 'calm', 'sad', 'calm',\n",
       "       'calm', 'fearful', 'disgust', 'angry', 'disgust', 'calm',\n",
       "       'disgust', 'surprised', 'fearful', 'calm', 'disgust', 'fearful',\n",
       "       'angry', 'calm', 'sad', 'fearful', 'calm', 'sad', 'calm',\n",
       "       'disgust', 'angry', 'sad', 'happy', 'disgust', 'disgust', 'calm',\n",
       "       'fearful', 'surprised', 'disgust', 'calm', 'fearful', 'surprised',\n",
       "       'disgust', 'calm', 'surprised', 'disgust', 'happy', 'surprised',\n",
       "       'calm', 'sad', 'calm', 'surprised', 'calm', 'fearful', 'surprised',\n",
       "       'calm', 'calm', 'surprised', 'disgust', 'calm', 'angry', 'calm',\n",
       "       'fearful', 'surprised', 'angry', 'angry', 'calm', 'surprised',\n",
       "       'angry', 'happy', 'sad', 'fearful', 'surprised', 'surprised',\n",
       "       'angry', 'fearful', 'calm', 'calm', 'fearful', 'happy', 'calm',\n",
       "       'angry', 'fearful', 'disgust', 'sad', 'angry', 'surprised',\n",
       "       'surprised', 'surprised', 'calm', 'calm', 'surprised', 'fearful',\n",
       "       'disgust', 'sad', 'happy', 'happy', 'surprised', 'surprised',\n",
       "       'angry', 'fearful', 'happy', 'surprised', 'angry', 'happy', 'calm',\n",
       "       'calm', 'happy', 'calm', 'sad', 'sad', 'angry', 'surprised',\n",
       "       'calm', 'disgust', 'surprised', 'fearful', 'calm', 'disgust',\n",
       "       'sad', 'calm', 'calm', 'calm', 'angry', 'surprised', 'surprised',\n",
       "       'happy', 'fearful', 'sad', 'calm', 'sad', 'sad', 'fearful',\n",
       "       'angry', 'disgust', 'disgust', 'disgust', 'calm', 'angry', 'calm',\n",
       "       'happy', 'disgust', 'surprised', 'calm', 'angry', 'fearful', 'sad',\n",
       "       'calm', 'angry', 'calm', 'happy', 'disgust', 'surprised', 'calm',\n",
       "       'calm', 'disgust', 'fearful', 'sad', 'fearful', 'fearful', 'calm',\n",
       "       'calm', 'sad', 'happy', 'happy', 'happy', 'calm', 'calm',\n",
       "       'disgust', 'angry', 'calm', 'happy', 'calm', 'surprised',\n",
       "       'fearful', 'angry', 'calm', 'sad', 'disgust', 'calm', 'calm',\n",
       "       'happy', 'angry', 'angry', 'surprised', 'disgust', 'sad',\n",
       "       'disgust', 'surprised', 'angry', 'surprised', 'disgust', 'calm',\n",
       "       'happy', 'surprised', 'happy', 'calm', 'surprised', 'happy',\n",
       "       'surprised', 'surprised', 'fearful', 'sad', 'happy', 'surprised',\n",
       "       'happy', 'calm', 'disgust', 'angry', 'angry', 'disgust', 'fearful',\n",
       "       'angry', 'surprised', 'sad', 'calm', 'happy', 'surprised', 'calm',\n",
       "       'angry', 'calm', 'happy', 'surprised', 'calm', 'angry', 'fearful',\n",
       "       'surprised', 'fearful', 'surprised', 'angry', 'calm', 'happy',\n",
       "       'sad', 'calm', 'sad', 'happy', 'surprised', 'sad', 'calm',\n",
       "       'fearful', 'happy', 'calm', 'calm', 'angry', 'angry', 'fearful',\n",
       "       'angry'], dtype='<U9')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = []\n",
    "# for emo in range(0, len(prediction)):\n",
    "#     if prediction[emo] == 0:\n",
    "#       res.append('angry')\n",
    "#     if prediction[emo] == 1:\n",
    "#       res.append('calm')\n",
    "#     if prediction[emo] == 2:\n",
    "#       res.append('disgust')\n",
    "#     if prediction[emo] == 3:\n",
    "#       res.append('fearful')\n",
    "#     if prediction[emo] == 4:\n",
    "#       res.append('happy')\n",
    "#     if prediction[emo] == 5:\n",
    "#       res.append('neutral')\n",
    "#     if prediction[emo] == 6:\n",
    "#       res.append('sad')\n",
    "#     if prediction[emo] == 7:\n",
    "#       res.append('surprised')\n",
    "# # print(NUM)\n",
    "# # print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(315,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['sample000', 'angry'],\n",
       "       ['sample001', 'angry'],\n",
       "       ['sample002', 'angry'],\n",
       "       ['sample003', 'angry'],\n",
       "       ['sample004', 'angry'],\n",
       "       ['sample005', 'angry'],\n",
       "       ['sample006', 'angry'],\n",
       "       ['sample007', 'angry'],\n",
       "       ['sample008', 'angry'],\n",
       "       ['sample009', 'angry'],\n",
       "       ['sample010', 'angry'],\n",
       "       ['sample011', 'sad'],\n",
       "       ['sample012', 'angry'],\n",
       "       ['sample013', 'surprised'],\n",
       "       ['sample014', 'angry'],\n",
       "       ['sample015', 'angry'],\n",
       "       ['sample016', 'angry'],\n",
       "       ['sample017', 'angry'],\n",
       "       ['sample018', 'angry'],\n",
       "       ['sample019', 'angry'],\n",
       "       ['sample020', 'angry'],\n",
       "       ['sample021', 'angry'],\n",
       "       ['sample022', 'angry'],\n",
       "       ['sample023', 'angry'],\n",
       "       ['sample024', 'angry'],\n",
       "       ['sample025', 'angry'],\n",
       "       ['sample026', 'angry'],\n",
       "       ['sample027', 'angry'],\n",
       "       ['sample028', 'angry'],\n",
       "       ['sample029', 'angry'],\n",
       "       ['sample030', 'happy'],\n",
       "       ['sample031', 'angry'],\n",
       "       ['sample032', 'angry'],\n",
       "       ['sample033', 'angry'],\n",
       "       ['sample034', 'calm'],\n",
       "       ['sample035', 'angry'],\n",
       "       ['sample036', 'angry'],\n",
       "       ['sample037', 'angry'],\n",
       "       ['sample038', 'angry'],\n",
       "       ['sample039', 'angry'],\n",
       "       ['sample040', 'angry'],\n",
       "       ['sample041', 'disgust'],\n",
       "       ['sample042', 'angry'],\n",
       "       ['sample043', 'angry'],\n",
       "       ['sample044', 'happy'],\n",
       "       ['sample045', 'disgust'],\n",
       "       ['sample046', 'angry'],\n",
       "       ['sample047', 'angry'],\n",
       "       ['sample048', 'angry'],\n",
       "       ['sample049', 'angry'],\n",
       "       ['sample050', 'angry'],\n",
       "       ['sample051', 'angry'],\n",
       "       ['sample052', 'angry'],\n",
       "       ['sample053', 'angry'],\n",
       "       ['sample054', 'angry'],\n",
       "       ['sample055', 'angry'],\n",
       "       ['sample056', 'angry'],\n",
       "       ['sample057', 'surprised'],\n",
       "       ['sample058', 'angry'],\n",
       "       ['sample059', 'angry'],\n",
       "       ['sample060', 'angry'],\n",
       "       ['sample061', 'angry'],\n",
       "       ['sample062', 'angry'],\n",
       "       ['sample063', 'surprised'],\n",
       "       ['sample064', 'angry'],\n",
       "       ['sample065', 'angry'],\n",
       "       ['sample066', 'fearful'],\n",
       "       ['sample067', 'angry'],\n",
       "       ['sample068', 'angry'],\n",
       "       ['sample069', 'angry'],\n",
       "       ['sample070', 'angry'],\n",
       "       ['sample071', 'angry'],\n",
       "       ['sample072', 'angry'],\n",
       "       ['sample073', 'angry'],\n",
       "       ['sample074', 'angry'],\n",
       "       ['sample075', 'fearful'],\n",
       "       ['sample076', 'angry'],\n",
       "       ['sample077', 'angry'],\n",
       "       ['sample078', 'angry'],\n",
       "       ['sample079', 'angry'],\n",
       "       ['sample080', 'angry'],\n",
       "       ['sample081', 'fearful'],\n",
       "       ['sample082', 'happy'],\n",
       "       ['sample083', 'angry'],\n",
       "       ['sample084', 'angry'],\n",
       "       ['sample085', 'angry'],\n",
       "       ['sample086', 'angry'],\n",
       "       ['sample087', 'fearful'],\n",
       "       ['sample088', 'angry'],\n",
       "       ['sample089', 'angry'],\n",
       "       ['sample090', 'angry'],\n",
       "       ['sample091', 'disgust'],\n",
       "       ['sample092', 'angry'],\n",
       "       ['sample093', 'disgust'],\n",
       "       ['sample094', 'angry'],\n",
       "       ['sample095', 'angry'],\n",
       "       ['sample096', 'angry'],\n",
       "       ['sample097', 'angry'],\n",
       "       ['sample098', 'disgust'],\n",
       "       ['sample099', 'angry'],\n",
       "       ['sample100', 'surprised'],\n",
       "       ['sample101', 'angry'],\n",
       "       ['sample102', 'angry'],\n",
       "       ['sample103', 'calm'],\n",
       "       ['sample104', 'angry'],\n",
       "       ['sample105', 'angry'],\n",
       "       ['sample106', 'angry'],\n",
       "       ['sample107', 'angry'],\n",
       "       ['sample108', 'angry'],\n",
       "       ['sample109', 'angry'],\n",
       "       ['sample110', 'surprised'],\n",
       "       ['sample111', 'angry'],\n",
       "       ['sample112', 'angry'],\n",
       "       ['sample113', 'surprised'],\n",
       "       ['sample114', 'happy'],\n",
       "       ['sample115', 'angry'],\n",
       "       ['sample116', 'angry'],\n",
       "       ['sample117', 'angry'],\n",
       "       ['sample118', 'angry'],\n",
       "       ['sample119', 'angry'],\n",
       "       ['sample120', 'angry'],\n",
       "       ['sample121', 'angry'],\n",
       "       ['sample122', 'angry'],\n",
       "       ['sample123', 'angry'],\n",
       "       ['sample124', 'angry'],\n",
       "       ['sample125', 'angry'],\n",
       "       ['sample126', 'angry'],\n",
       "       ['sample127', 'angry'],\n",
       "       ['sample128', 'angry'],\n",
       "       ['sample129', 'angry'],\n",
       "       ['sample130', 'angry'],\n",
       "       ['sample131', 'angry'],\n",
       "       ['sample132', 'angry'],\n",
       "       ['sample133', 'angry'],\n",
       "       ['sample134', 'angry'],\n",
       "       ['sample135', 'surprised'],\n",
       "       ['sample136', 'angry'],\n",
       "       ['sample137', 'angry'],\n",
       "       ['sample138', 'angry'],\n",
       "       ['sample139', 'angry'],\n",
       "       ['sample140', 'angry'],\n",
       "       ['sample141', 'angry'],\n",
       "       ['sample142', 'angry'],\n",
       "       ['sample143', 'angry'],\n",
       "       ['sample144', 'angry'],\n",
       "       ['sample145', 'surprised'],\n",
       "       ['sample146', 'angry'],\n",
       "       ['sample147', 'angry'],\n",
       "       ['sample148', 'angry'],\n",
       "       ['sample149', 'angry'],\n",
       "       ['sample150', 'calm'],\n",
       "       ['sample151', 'calm'],\n",
       "       ['sample152', 'surprised'],\n",
       "       ['sample153', 'calm'],\n",
       "       ['sample154', 'calm'],\n",
       "       ['sample155', 'calm'],\n",
       "       ['sample156', 'calm'],\n",
       "       ['sample157', 'calm'],\n",
       "       ['sample158', 'calm'],\n",
       "       ['sample159', 'calm'],\n",
       "       ['sample160', 'calm'],\n",
       "       ['sample161', 'calm'],\n",
       "       ['sample162', 'calm'],\n",
       "       ['sample163', 'calm'],\n",
       "       ['sample164', 'calm'],\n",
       "       ['sample165', 'calm'],\n",
       "       ['sample166', 'calm'],\n",
       "       ['sample167', 'calm'],\n",
       "       ['sample168', 'calm'],\n",
       "       ['sample169', 'calm'],\n",
       "       ['sample170', 'calm'],\n",
       "       ['sample171', 'calm'],\n",
       "       ['sample172', 'calm'],\n",
       "       ['sample173', 'calm'],\n",
       "       ['sample174', 'calm'],\n",
       "       ['sample175', 'calm'],\n",
       "       ['sample176', 'calm'],\n",
       "       ['sample177', 'calm'],\n",
       "       ['sample178', 'sad'],\n",
       "       ['sample179', 'calm'],\n",
       "       ['sample180', 'calm'],\n",
       "       ['sample181', 'calm'],\n",
       "       ['sample182', 'disgust'],\n",
       "       ['sample183', 'calm'],\n",
       "       ['sample184', 'calm'],\n",
       "       ['sample185', 'calm'],\n",
       "       ['sample186', 'calm'],\n",
       "       ['sample187', 'calm'],\n",
       "       ['sample188', 'surprised'],\n",
       "       ['sample189', 'calm'],\n",
       "       ['sample190', 'calm'],\n",
       "       ['sample191', 'calm'],\n",
       "       ['sample192', 'calm'],\n",
       "       ['sample193', 'calm'],\n",
       "       ['sample194', 'disgust'],\n",
       "       ['sample195', 'calm'],\n",
       "       ['sample196', 'calm'],\n",
       "       ['sample197', 'calm'],\n",
       "       ['sample198', 'calm'],\n",
       "       ['sample199', 'calm'],\n",
       "       ['sample200', 'calm'],\n",
       "       ['sample201', 'calm'],\n",
       "       ['sample202', 'calm'],\n",
       "       ['sample203', 'calm'],\n",
       "       ['sample204', 'neutral'],\n",
       "       ['sample205', 'calm'],\n",
       "       ['sample206', 'calm'],\n",
       "       ['sample207', 'calm'],\n",
       "       ['sample208', 'sad'],\n",
       "       ['sample209', 'calm'],\n",
       "       ['sample210', 'calm'],\n",
       "       ['sample211', 'disgust'],\n",
       "       ['sample212', 'calm'],\n",
       "       ['sample213', 'fearful'],\n",
       "       ['sample214', 'calm'],\n",
       "       ['sample215', 'calm'],\n",
       "       ['sample216', 'calm'],\n",
       "       ['sample217', 'calm'],\n",
       "       ['sample218', 'calm'],\n",
       "       ['sample219', 'calm'],\n",
       "       ['sample220', 'neutral'],\n",
       "       ['sample221', 'calm'],\n",
       "       ['sample222', 'calm'],\n",
       "       ['sample223', 'calm'],\n",
       "       ['sample224', 'calm'],\n",
       "       ['sample225', 'calm'],\n",
       "       ['sample226', 'calm'],\n",
       "       ['sample227', 'angry'],\n",
       "       ['sample228', 'calm'],\n",
       "       ['sample229', 'calm'],\n",
       "       ['sample230', 'calm'],\n",
       "       ['sample231', 'calm'],\n",
       "       ['sample232', 'calm'],\n",
       "       ['sample233', 'calm'],\n",
       "       ['sample234', 'calm'],\n",
       "       ['sample235', 'calm'],\n",
       "       ['sample236', 'disgust'],\n",
       "       ['sample237', 'calm'],\n",
       "       ['sample238', 'calm'],\n",
       "       ['sample239', 'calm'],\n",
       "       ['sample240', 'disgust'],\n",
       "       ['sample241', 'calm'],\n",
       "       ['sample242', 'calm'],\n",
       "       ['sample243', 'calm'],\n",
       "       ['sample244', 'calm'],\n",
       "       ['sample245', 'calm'],\n",
       "       ['sample246', 'calm'],\n",
       "       ['sample247', 'calm'],\n",
       "       ['sample248', 'calm'],\n",
       "       ['sample249', 'calm'],\n",
       "       ['sample250', 'calm'],\n",
       "       ['sample251', 'calm'],\n",
       "       ['sample252', 'calm'],\n",
       "       ['sample253', 'disgust'],\n",
       "       ['sample254', 'calm'],\n",
       "       ['sample255', 'calm'],\n",
       "       ['sample256', 'calm'],\n",
       "       ['sample257', 'calm'],\n",
       "       ['sample258', 'neutral'],\n",
       "       ['sample259', 'calm'],\n",
       "       ['sample260', 'calm'],\n",
       "       ['sample261', 'calm'],\n",
       "       ['sample262', 'calm'],\n",
       "       ['sample263', 'calm'],\n",
       "       ['sample264', 'calm'],\n",
       "       ['sample265', 'surprised'],\n",
       "       ['sample266', 'calm'],\n",
       "       ['sample267', 'calm'],\n",
       "       ['sample268', 'calm'],\n",
       "       ['sample269', 'calm'],\n",
       "       ['sample270', 'calm'],\n",
       "       ['sample271', 'calm'],\n",
       "       ['sample272', 'calm'],\n",
       "       ['sample273', 'calm'],\n",
       "       ['sample274', 'calm'],\n",
       "       ['sample275', 'calm'],\n",
       "       ['sample276', 'calm'],\n",
       "       ['sample277', 'calm'],\n",
       "       ['sample278', 'calm'],\n",
       "       ['sample279', 'calm'],\n",
       "       ['sample280', 'calm'],\n",
       "       ['sample281', 'calm'],\n",
       "       ['sample282', 'calm'],\n",
       "       ['sample283', 'happy'],\n",
       "       ['sample284', 'calm'],\n",
       "       ['sample285', 'calm'],\n",
       "       ['sample286', 'calm'],\n",
       "       ['sample287', 'calm'],\n",
       "       ['sample288', 'calm'],\n",
       "       ['sample289', 'calm'],\n",
       "       ['sample290', 'calm'],\n",
       "       ['sample291', 'calm'],\n",
       "       ['sample292', 'sad'],\n",
       "       ['sample293', 'calm'],\n",
       "       ['sample294', 'calm'],\n",
       "       ['sample295', 'calm'],\n",
       "       ['sample296', 'calm'],\n",
       "       ['sample297', 'calm'],\n",
       "       ['sample298', 'calm'],\n",
       "       ['sample299', 'sad'],\n",
       "       ['sample300', 'disgust'],\n",
       "       ['sample301', 'disgust'],\n",
       "       ['sample302', 'angry'],\n",
       "       ['sample303', 'happy'],\n",
       "       ['sample304', 'calm'],\n",
       "       ['sample305', 'disgust'],\n",
       "       ['sample306', 'fearful'],\n",
       "       ['sample307', 'fearful'],\n",
       "       ['sample308', 'happy'],\n",
       "       ['sample309', 'disgust'],\n",
       "       ['sample310', 'angry'],\n",
       "       ['sample311', 'disgust'],\n",
       "       ['sample312', 'angry'],\n",
       "       ['sample313', 'neutral'],\n",
       "       ['sample314', 'disgust']], dtype='<U9')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = np.array(prediction).transpose()\n",
    "NUM = np.array(NUM).transpose()\n",
    "sample = np.column_stack([NUM, res])\n",
    "sort_sample = sample[sample[:, 0].argsort()]\n",
    "name = []\n",
    "for item in sort_sample[:,0]:\n",
    "  item = 'sample'+str(item)\n",
    "  name.append(item)\n",
    "name = np.array(name).transpose()\n",
    "sort_sample[:,0] = name\n",
    "sort_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../../\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Weili Fan\\\\Documents\\\\all\\\\rice\\\\courses\\\\2022 Fall\\\\ELEC 301\\\\project'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DF = pd.DataFrame(sort_sample)\n",
    "DF.columns = ['filename', 'label']\n",
    "DF.to_csv(\"mfcc 39 SVM C = 10.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1069c1e00a215b1f02473d6a16c0760db8a56168728b44b16b6ac804c935dc98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
