{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAF7an2rBhN7"
      },
      "outputs": [],
      "source": [
        "!pwd\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMwgHbmx15-E"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/ELEC301\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUI5N8w-2AIk"
      },
      "outputs": [],
      "source": [
        "!unzip 'data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQRY-EKLEVX9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gs5UiRjEJEt"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/ELEC301/data\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuGa94YUEtsM"
      },
      "outputs": [],
      "source": [
        "# Time Domain Data\n",
        "data_t = []\n",
        "label = []\n",
        "for filename in os.listdir():\n",
        "    fs, data = wavfile.read(filename)\n",
        "    if len(data.shape) > 1:\n",
        "        data = data[:, 0]\n",
        "    data = data.astype(float)\n",
        "    data_t.append(data)\n",
        "    label.append(str(filename[: -7]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yihh-aGEjEXq"
      },
      "outputs": [],
      "source": [
        "threshold = 0.1\n",
        "cut = []\n",
        "for i in range(1125):\n",
        "  effect = data_t[i][np.argwhere(data_t[i]/max(data_t[i]) > threshold)[0,0]:np.argwhere(data_t[i]/max(data_t[i]) > threshold)[-1,0]+1]\n",
        "  cut.append(effect)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgpYeKj6t1pn"
      },
      "outputs": [],
      "source": [
        "# Put Data Into 2D Matrix\n",
        "D = []\n",
        "maxl = 0\n",
        "for i in range(1125):\n",
        "  print(len(cut[i]))\n",
        "  seg_data = []\n",
        "  for j in range(10):\n",
        "    data = cut[i]\n",
        "    seg = int(len(data)/(10))\n",
        "    if j < (9):\n",
        "      seg_data.append(data[j*seg:j*seg+seg])\n",
        "    else:\n",
        "      seg_data.append(data[9*seg:-1])\n",
        "  D.append(seg_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmZuMdT1wzON"
      },
      "outputs": [],
      "source": [
        "D = np.array(D)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqnyt9G_xd11"
      },
      "outputs": [],
      "source": [
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    if len(D[i,j]) > maxl:\n",
        "      maxl = len(D[i,j])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "min"
      ],
      "metadata": {
        "id": "QbXjptj75-Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KDhcHYnGxGx"
      },
      "outputs": [],
      "source": [
        "data_pad = [] # Time Domain Data\n",
        "for i in range(1125):\n",
        "  zero_pad = np.zeros((10, maxl))\n",
        "  for j in range(10):\n",
        "    zero_pad[j, range(0, len(D[i,j]))] = D[i,j]\n",
        "    #zero_pad[j] = D[i,j][range(min)]\n",
        "  data_pad.append(zero_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RkDZzVm5ze35"
      },
      "outputs": [],
      "source": [
        "data_pad = np.array(data_pad)\n",
        "data_pad.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRhBfazSS2Qy"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "from librosa import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkT1gaQwJzXe"
      },
      "outputs": [],
      "source": [
        "# MFCC\n",
        "MFCC = np.zeros((1125,96,32,10))\n",
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    MFCC[i,:,:,j] = (librosa.feature.mfcc(y=data_pad[i,j], sr=fs, n_mfcc = 32*3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7JfBr9nb1G3"
      },
      "outputs": [],
      "source": [
        "# MFCC_11250\n",
        "MFCC = []\n",
        "for i in range(1125):\n",
        "  mid = []\n",
        "  print(i)\n",
        "  for j in range(10):\n",
        "    mid.append(librosa.feature.mfcc(y=D[i,j], sr=fs, n_mfcc = 32))\n",
        "  MFCC.append(mid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veVHBBREQKpl"
      },
      "outputs": [],
      "source": [
        "# Chroma\n",
        "Chroma = np.zeros((1125,96,32,10))\n",
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    Chroma[i,:,:,j] = (librosa.feature.chroma_stft(y=data_pad[i,j], sr=fs, n_chroma = 32*3))\n",
        "  print(i)\n",
        "Chroma = np.array(Chroma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aAW51ddcJd8"
      },
      "outputs": [],
      "source": [
        "# Chroma_11250\n",
        "Chroma = []\n",
        "for i in range(1125):\n",
        "  mid=[]\n",
        "  for j in range(10):\n",
        "    mid.append(librosa.feature.chroma_stft(y=data_pad[i,j], sr=fs, n_chroma = 32))\n",
        "  Chroma.append(mid)\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ro3ZRmxwRql8"
      },
      "outputs": [],
      "source": [
        "# Mel Spectrogram\n",
        "MELS = np.zeros((1125,96,32,10))\n",
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    MELS[i,:,:,j] = (librosa.feature.melspectrogram(y=data_pad[i,j], sr=fs, n_mels = 32*3))\n",
        "  MELS = np.array(MELS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNnGLi7-cb0s"
      },
      "outputs": [],
      "source": [
        "# Mel Spectrogram_11250\n",
        "MELS = []\n",
        "for i in range(1125):\n",
        "  print(i)\n",
        "  mid = []\n",
        "  for j in range(10):\n",
        "    mid.append(librosa.feature.melspectrogram(y=data_pad[i,j], sr=fs, n_mels = 32))\n",
        "  MELS.append(mid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkHIe7GFZWP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2d9f2d-5311-4ef2-8e9c-c86c8411df8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1125, 96, 32, 10)\n",
            "(1125, 96, 32, 10)\n",
            "(1125, 96, 32, 10)\n"
          ]
        }
      ],
      "source": [
        "print(MELS.shape)\n",
        "print(Chroma.shape)\n",
        "print(MFCC.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(MFCC[0][0])"
      ],
      "metadata": {
        "id": "H3iJC8kYl_ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RED=np.zeros((1125,10,32,6))\n",
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    mid1=[]\n",
        "    mid2=[]\n",
        "    mid3=[]\n",
        "    ave = np.mean(MFCC[i][j],axis=1)\n",
        "    vari = np.var(MFCC[i][j],axis=1)\n",
        "    mid1.append(ave)\n",
        "    mid1.append(vari)\n",
        "    ave = np.mean(Chroma[i][j],axis=1)\n",
        "    vari = np.var(Chroma[i][j],axis=1)\n",
        "    mid2.append(ave)\n",
        "    mid2.append(vari)\n",
        "    ave = np.mean(MELS[i][j],axis=1)\n",
        "    vari = np.var(MELS[i][j],axis=1)\n",
        "    mid3.append(ave)\n",
        "    mid3.append(vari)\n",
        "    mid1=np.array(mid1).transpose()\n",
        "    mid2=np.array(mid2).transpose()\n",
        "    mid3=np.array(mid3).transpose()\n",
        "    val=np.column_stack([mid1,mid2,mid3])\n",
        "    RED[i,j] = val\n"
      ],
      "metadata": {
        "id": "dRcsTXsAkRp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3y8RJMndsQi"
      },
      "outputs": [],
      "source": [
        "DATA_M = []\n",
        "for i in range(1125):\n",
        "  for j in range(10):\n",
        "    mat = np.column_stack([MFCC[i],Chroma[i],MELS[i]])\n",
        "    DATA_M.append(mat)\n",
        "DATA_M=np.array(DATA_M)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_M = np.zeros((11250, 12, 10, 3))\n",
        "for i in range(11250):\n",
        "  DATA_M[i,:,:,0] = MFCC[i]\n",
        "  DATA_M[i,:,:,1] = Chroma[i]\n",
        "  DATA_M[i,:,:,2] = MELS[i]"
      ],
      "metadata": {
        "id": "jAEmX8s9Cu4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwNRCqXPheyO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05debcbf-cdcb-45ec-efb5-657c93f0a12b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11250, 96, 96)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "DATA_M.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPEL_biyM7Xc"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(nrows=2, sharex=True)\n",
        "img = librosa.display.specshow(res,\n",
        "                               x_axis='time', y_axis='mel', fmax=8000,\n",
        "                               ax=ax[0])\n",
        "fig.colorbar(img, ax=[ax[0]])\n",
        "ax[0].set(title='Mel spectrogram')\n",
        "ax[0].label_outer()\n",
        "img = librosa.display.specshow(res2, x_axis='time', ax=ax[1])\n",
        "fig.colorbar(img, ax=[ax[1]])\n",
        "ax[1].set(title='MFCC')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUKVH9BVSyLF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from python_speech_features import mfcc\n",
        "MFCC = []\n",
        "for i in range(1125):\n",
        "  mid = []\n",
        "  for j in range(6):\n",
        "    features_mfcc = mfcc(D[i][j], fs, nfft=1200)\n",
        "    features_mfcc = features_mfcc[:, 1:]\n",
        "    features_mfcc = features_mfcc.T\n",
        "    mfcc_processed = np.column_stack([np.mean(features_mfcc,axis=1), np.var(features_mfcc,axis=1)])\n",
        "    mid.append(mfcc_processed)\n",
        "  MFCC.append(mid)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHa7WpQdIwV9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGoLACXYI41K"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def get_spectrogram(waveform):\n",
        "    #spectrogram = tf.signal.stft(waveform, frame_length=512, frame_step=128)\n",
        "    spectrogram = tf.signal.stft(waveform, frame_length=128, frame_step=512)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = spectrogram[..., tf.newaxis]\n",
        "    return spectrogram\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hGPL38yNdvQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SPEC = []\n",
        "for i in range(1125):\n",
        "  print(i)\n",
        "  mid = []\n",
        "  for j in range(6):\n",
        "    waveform = data_pad[i][j]\n",
        "    spectrogram = get_spectrogram(waveform)\n",
        "    mid.append(spectrogram)\n",
        "  SPEC.append(mid)\n",
        "\n",
        "spectrogram.shape\n",
        "  #print('Label:', label_name)\n",
        "  #print('Waveform shape:', waveform.shape)\n",
        "  #print('Spectrogram shape:', spectrogram.shape)\n",
        "  #print('Audio playback')\n",
        "  #display.display(display.Audio(waveform, rate=48000))\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "boOfsjcC58sD"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "DATA = np.zeros((1125,53,65,6))\n",
        "for i in range(1125):\n",
        "  for j in range(53):\n",
        "    for k in range(65):\n",
        "      for m in range(6):\n",
        "        DATA[i,j,k,m] = SPEC[i,m,j,k]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpFd6dTtQ0oZ"
      },
      "outputs": [],
      "source": [
        "# Make Number Label (1125)\n",
        "Y = []\n",
        "for emo in range(0, len(label)):\n",
        "    if label[emo] == 'angry':\n",
        "        Y.append(0)\n",
        "    if label[emo] == 'calm':\n",
        "        Y.append(1)\n",
        "    if label[emo] == 'disgust':\n",
        "        Y.append(2)\n",
        "    if label[emo] == 'fearful':\n",
        "        Y.append(3)\n",
        "    if label[emo] == 'happy':\n",
        "        Y.append(4)\n",
        "    if label[emo] == 'neutral':\n",
        "        Y.append(5)\n",
        "    if label[emo] == 'sad':\n",
        "        Y.append(6)\n",
        "    if label[emo] == 'surprised':\n",
        "        Y.append(7)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQIMuVlKYr37"
      },
      "outputs": [],
      "source": [
        "# Make Number Label\n",
        "Y = []\n",
        "for emo in range(0, len(label)):\n",
        "    if label[emo] == 'angry':\n",
        "      for i in range(10):\n",
        "        Y.append(0)\n",
        "    if label[emo] == 'calm':\n",
        "      for i in range(10):\n",
        "        Y.append(1)\n",
        "    if label[emo] == 'disgust':\n",
        "      for i in range(10):\n",
        "        Y.append(2)\n",
        "    if label[emo] == 'fearful':\n",
        "      for i in range(10):\n",
        "        Y.append(3)\n",
        "    if label[emo] == 'happy':\n",
        "      for i in range(10):\n",
        "        Y.append(4)\n",
        "    if label[emo] == 'neutral':\n",
        "      for i in range(10):\n",
        "        Y.append(5)\n",
        "    if label[emo] == 'sad':\n",
        "      for i in range(10):\n",
        "        Y.append(6)\n",
        "    if label[emo] == 'surprised':\n",
        "      for i in range(10):\n",
        "        Y.append(7)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7QrZJr5kkRB"
      },
      "outputs": [],
      "source": [
        "DATA = np.zeros((11250,96,96,1))\n",
        "for i in range(11250):\n",
        "  print(i)\n",
        "  for j in range(96):\n",
        "    for k in range(96):\n",
        "      DATA[i,j,k,0] = DATA_M[i,j,k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLIBCVmmqDtz"
      },
      "outputs": [],
      "source": [
        "DATA.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj-9EronY6vc"
      },
      "outputs": [],
      "source": [
        "# Select Training and Test Data\n",
        "random_traning_data = np.random.choice(len(Y), 2000, replace=False)\n",
        "train_data = DATA[random_traning_data]\n",
        "train_label = Y[random_traning_data]\n",
        "remaining_data = np.setdiff1d(range(0, len(Y)), random_traning_data)\n",
        "test_data = DATA[remaining_data]\n",
        "test_label = Y[remaining_data]\n",
        "len(test_label)+len(train_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGzdgCVpZSFb"
      },
      "outputs": [],
      "source": [
        "input_shape = DATA.shape[1:]\n",
        "num_labels = 8\n",
        "# Instantiate the `tf.keras.layers.Normalization` layer.\n",
        "norm_layer = layers.Normalization()\n",
        "norm_layer.adapt(train_data)\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=input_shape),\n",
        "\n",
        "    #Downsample the input.\n",
        "    #layers.Resizing(10, 10),\n",
        "\n",
        "    norm_layer,\n",
        "    layers.Conv2D(32, 5, activation='softmax'),\n",
        "    #layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 5, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 5, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 5, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 5, activation='relu'),\n",
        "    layers.Dropout(0.25),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_labels),\n",
        "])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "720bkO1jb1Ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "outputId": "2e20cb0b-03f4-4ce1-9b5e-bcecd733a03a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "63/63 [==============================] - 170s 3s/step - loss: 2.0704 - accuracy: 0.1330 - val_loss: 2.0147 - val_accuracy: 0.1342\n",
            "Epoch 2/100\n",
            "63/63 [==============================] - 164s 3s/step - loss: 2.0378 - accuracy: 0.1590 - val_loss: 1.9837 - val_accuracy: 0.1734\n",
            "Epoch 3/100\n",
            "63/63 [==============================] - 163s 3s/step - loss: 1.9982 - accuracy: 0.1745 - val_loss: 1.9583 - val_accuracy: 0.1836\n",
            "Epoch 4/100\n",
            "63/63 [==============================] - 166s 3s/step - loss: 1.9737 - accuracy: 0.1940 - val_loss: 1.9487 - val_accuracy: 0.1808\n",
            "Epoch 5/100\n",
            "63/63 [==============================] - 166s 3s/step - loss: 1.9525 - accuracy: 0.2145 - val_loss: 1.9102 - val_accuracy: 0.2579\n",
            "Epoch 6/100\n",
            "63/63 [==============================] - 166s 3s/step - loss: 1.9088 - accuracy: 0.2085 - val_loss: 1.9112 - val_accuracy: 0.2411\n",
            "Epoch 7/100\n",
            "63/63 [==============================] - 165s 3s/step - loss: 1.9097 - accuracy: 0.2200 - val_loss: 1.8734 - val_accuracy: 0.2577\n",
            "Epoch 8/100\n",
            "63/63 [==============================] - 165s 3s/step - loss: 1.8879 - accuracy: 0.2115 - val_loss: 1.8648 - val_accuracy: 0.2565\n",
            "Epoch 9/100\n",
            "63/63 [==============================] - 165s 3s/step - loss: 1.8771 - accuracy: 0.2415 - val_loss: 1.8568 - val_accuracy: 0.2681\n",
            "Epoch 10/100\n",
            "63/63 [==============================] - 165s 3s/step - loss: 1.8556 - accuracy: 0.2495 - val_loss: 1.8429 - val_accuracy: 0.2723\n",
            "Epoch 11/100\n",
            "63/63 [==============================] - 175s 3s/step - loss: 1.8482 - accuracy: 0.2610 - val_loss: 1.8522 - val_accuracy: 0.2662\n",
            "Epoch 12/100\n",
            "63/63 [==============================] - ETA: 0s - loss: 1.8277 - accuracy: 0.2605"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-46b9117a7754>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     metrics=['accuracy'])\n\u001b[1;32m      5\u001b[0m history = model.fit(\n\u001b[0;32m----> 6\u001b[0;31m     train_data, train_label, epochs=100, validation_data=(test_data, test_label))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1454\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[1;32m   1457\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])\n",
        "history = model.fit(\n",
        "    train_data, train_label, epochs=100, validation_data=(test_data, test_label))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNX9xtXlysfs",
        "outputId": "fe55f836-8400-4d7f-a06c-ecd2ba642f85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBqUkGuZYqZr"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend(loc='lower right')\n",
        "test_loss, test_acc = model.evaluate(test_data,  test_label, verbose=2)\n",
        "print(test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrWD0BgPYvcX"
      },
      "source": [
        "PREDICTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2_jCVQhYuj0"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/ELEC301/test\"\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NADoygZY8Rr"
      },
      "outputs": [],
      "source": [
        "# Time Domain Data\n",
        "data_test = []\n",
        "label_test = []\n",
        "NUM = []\n",
        "L_test = [] # length of each audio\n",
        "for filename in os.listdir():\n",
        "    label_test.append(str(filename[: -7]))\n",
        "    fs, data = wavfile.read(filename)\n",
        "    if len(data.shape) > 1:\n",
        "        data = data[:, 0]\n",
        "    data = data.astype(float)\n",
        "    data_test.append(data)\n",
        "    L_test.append(len(data))\n",
        "    NUM.append(str(filename[6: 9]))\n",
        "print(L_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DirPjG5zaL97"
      },
      "outputs": [],
      "source": [
        "for i in range(315):\n",
        "  data_test[i] = data_test[i].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3YtjAwXc3Mz",
        "outputId": "b61e0524-db57-4bb5-8d04-0d7678627982"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5823.0"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test[0][148197]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIFyeCL9ZGhK"
      },
      "outputs": [],
      "source": [
        "cut = []\n",
        "for i in range(315):\n",
        "  posi = np.argmax(data_test[i])\n",
        "  small = np.argwhere(data_test[i]/data_test[i][posi] > 0.1)[0,0]\n",
        "  big = np.argwhere(data_test[i]/data_test[i][posi] > 0.1)[-1,0]\n",
        "  eff = data_test[i][small : big+1]\n",
        "  cut.append(eff)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdCQU4Z4dr5S"
      },
      "outputs": [],
      "source": [
        "# Put Data Into 2D Matrix\n",
        "D_test = []\n",
        "for i in range(315):\n",
        "  seg_data = []\n",
        "  for j in range(6):\n",
        "    data = cut[i]\n",
        "    seg = int(len(data)/(6))\n",
        "    if j < (5):\n",
        "      seg_data.append(data[j*seg:j*seg+seg])\n",
        "    else:\n",
        "      seg_data.append(data[5*seg:-1])\n",
        "  D_test.append(seg_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ED4taTJd5ub"
      },
      "outputs": [],
      "source": [
        "D_test = np.array(D_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-obm8jVd84R"
      },
      "outputs": [],
      "source": [
        "D_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlfmHQTkeCf-"
      },
      "outputs": [],
      "source": [
        "max = 0\n",
        "for i in range(315):\n",
        "  for j in range(6):\n",
        "    if len(D_test[i,j]) > max:\n",
        "      max = len(D_test[i,j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgBnKfnZeRi7"
      },
      "outputs": [],
      "source": [
        "data_pad1 = [] # Time Domain Data\n",
        "for i in range(315):\n",
        "  zero_pad = np.zeros((6, 27162))\n",
        "  for j in range(6):\n",
        "    zero_pad[j, range(0, len(D_test[i,j]))] = D_test[i,j]\n",
        "  data_pad1.append(zero_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBop4cm1etLI",
        "outputId": "c6bc0752-0b8c-4845-dfa5-6a2f45422410"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(315, 6, 27162)"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_pad1 = np.array(data_pad1)\n",
        "data_pad1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4utYm0PTe0WT"
      },
      "outputs": [],
      "source": [
        "# MFCC\n",
        "MFCC_test = []\n",
        "for i in range(315):\n",
        "  mid = []\n",
        "  for j in range(6):\n",
        "    features_mfcc = mfcc(data_pad1[i][j], fs, nfft=1200)\n",
        "    features_mfcc = features_mfcc[:, 1:]\n",
        "    features_mfcc = features_mfcc.T\n",
        "    mfcc_processed = np.column_stack([np.mean(features_mfcc,axis=1), np.var(features_mfcc,axis=1)])\n",
        "    mid.append(mfcc_processed)\n",
        "  MFCC_test.append(mid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAJE3eFGfDFP",
        "outputId": "15886e0b-fcbf-4893-edd1-4e1c4d569697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(315, 6, 12, 2)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MFCC_test = np.array(MFCC_test)\n",
        "MFCC_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCl_Gr_pfbE8"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(MFCC_test)\n",
        "score = tf.nn.softmax(predictions)\n",
        "label_predict = []\n",
        "for i in range(315):\n",
        "  label_predict.append(np.argmax(score[i]))\n",
        "\n",
        "label_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZuWqes9fr9q"
      },
      "outputs": [],
      "source": [
        "res = []\n",
        "for emo in range(0, len(label_predict)):\n",
        "    if label_predict[emo] == 0:\n",
        "      res.append('angry')\n",
        "    if label_predict[emo] == 1:\n",
        "      res.append('calm')\n",
        "    if label_predict[emo] == 2:\n",
        "      res.append('disgust')\n",
        "    if label_predict[emo] == 3:\n",
        "      res.append('fearful')\n",
        "    if label_predict[emo] == 4:\n",
        "      res.append('happy')\n",
        "    if label_predict[emo] == 5:\n",
        "      res.append('neutral')\n",
        "    if label_predict[emo] == 6:\n",
        "      res.append('sad')\n",
        "    if label_predict[emo] == 7:\n",
        "      res.append('surprised')\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3_g5bnTfxQu"
      },
      "outputs": [],
      "source": [
        "res = np.array(res).transpose()\n",
        "NUM = np.array(NUM).transpose()\n",
        "sample = np.column_stack([NUM, res])\n",
        "sort_sample = sample[sample[:, 0].argsort()]\n",
        "name = []\n",
        "for item in sort_sample[:,0]:\n",
        "  item = 'sample'+str(item)\n",
        "  name.append(item)\n",
        "name = np.array(name).transpose()\n",
        "sort_sample[:,0] = name\n",
        "sort_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccixcPm6gDyL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "DF = pd.DataFrame(sort_sample)\n",
        "DF.to_csv(\"res.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBa6kt8EZPyU"
      },
      "source": [
        "RNN BELOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5yLGxRqTWT89"
      },
      "outputs": [],
      "source": [
        "batch_size = 192\n",
        "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
        "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
        "input_dim = 96\n",
        "\n",
        "units = 192\n",
        "output_size = 8  # labels are from 0 to 7\n",
        "def build_model(allow_cudnn_kernel=True):\n",
        "    # CuDNN is only available at the layer level, and not at the cell level.\n",
        "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
        "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
        "    if allow_cudnn_kernel:\n",
        "        # The LSTM layer with default options uses CuDNN.\n",
        "        lstm_layer = layers.LSTM(units, input_shape=(None, input_dim))\n",
        "    else:\n",
        "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
        "        lstm_layer = layers.RNN(\n",
        "            layers.LSTMCell(units), input_shape=(None, input_dim)\n",
        "        )\n",
        "    model = models.Sequential(\n",
        "        [\n",
        "            lstm_layer,\n",
        "            layers.BatchNormalization(),\n",
        "            layers.Dense(output_size),\n",
        "        ]\n",
        "    )\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(allow_cudnn_kernel=True)\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    train_data, train_label, epochs=100, batch_size=batch_size, validation_data=(test_data, test_label))"
      ],
      "metadata": {
        "id": "2prOGSrqp0KT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
        "noncudnn_model.set_weights(model.get_weights())\n",
        "noncudnn_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=\"sgd\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "history = model.fit(\n",
        "    train_data, train_label, epochs=100, batch_size=batch_size, validation_data=(test_data, test_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FsznQBIh0GPf",
        "outputId": "9e9cf1dd-bfe0-4511-8a87-2c7986b4691b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 7s 640ms/step - loss: 2.0215 - accuracy: 0.2435 - val_loss: 2.0507 - val_accuracy: 0.2218\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 7s 627ms/step - loss: 1.9734 - accuracy: 0.2645 - val_loss: 2.0365 - val_accuracy: 0.2396\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 7s 628ms/step - loss: 1.9278 - accuracy: 0.2880 - val_loss: 2.0116 - val_accuracy: 0.2409\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 1.9080 - accuracy: 0.2875 - val_loss: 1.9922 - val_accuracy: 0.2493\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 7s 636ms/step - loss: 1.9077 - accuracy: 0.2795 - val_loss: 1.9943 - val_accuracy: 0.2427\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 7s 614ms/step - loss: 1.8871 - accuracy: 0.2840 - val_loss: 1.9819 - val_accuracy: 0.2422\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 7s 617ms/step - loss: 1.8744 - accuracy: 0.2965 - val_loss: 1.9951 - val_accuracy: 0.2511\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 7s 621ms/step - loss: 1.8690 - accuracy: 0.2975 - val_loss: 1.9933 - val_accuracy: 0.2511\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 7s 627ms/step - loss: 1.8600 - accuracy: 0.2975 - val_loss: 1.9978 - val_accuracy: 0.2636\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 1.8603 - accuracy: 0.2965 - val_loss: 2.0057 - val_accuracy: 0.2507\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 7s 629ms/step - loss: 1.8422 - accuracy: 0.3055 - val_loss: 2.0191 - val_accuracy: 0.2462\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 7s 687ms/step - loss: 1.8471 - accuracy: 0.3015 - val_loss: 2.0177 - val_accuracy: 0.2498\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 7s 630ms/step - loss: 1.8280 - accuracy: 0.3075 - val_loss: 2.0077 - val_accuracy: 0.2547\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 7s 619ms/step - loss: 1.8282 - accuracy: 0.3130 - val_loss: 2.0187 - val_accuracy: 0.2507\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 1.8174 - accuracy: 0.3200 - val_loss: 1.9871 - val_accuracy: 0.2609\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 7s 626ms/step - loss: 1.8202 - accuracy: 0.3280 - val_loss: 1.9815 - val_accuracy: 0.2640\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 7s 623ms/step - loss: 1.8061 - accuracy: 0.3290 - val_loss: 1.9772 - val_accuracy: 0.2671\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 7s 632ms/step - loss: 1.8007 - accuracy: 0.3250 - val_loss: 1.9819 - val_accuracy: 0.2671\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 7s 623ms/step - loss: 1.7961 - accuracy: 0.3230 - val_loss: 1.9790 - val_accuracy: 0.2644\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 7s 624ms/step - loss: 1.7918 - accuracy: 0.3270 - val_loss: 1.9696 - val_accuracy: 0.2662\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 7s 624ms/step - loss: 1.7846 - accuracy: 0.3370 - val_loss: 1.9672 - val_accuracy: 0.2618\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 7s 625ms/step - loss: 1.7741 - accuracy: 0.3350 - val_loss: 1.9617 - val_accuracy: 0.2751\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 1.7687 - accuracy: 0.3405 - val_loss: 1.9638 - val_accuracy: 0.2684\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 7s 628ms/step - loss: 1.7707 - accuracy: 0.3430 - val_loss: 1.9672 - val_accuracy: 0.2613\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 7s 621ms/step - loss: 1.7549 - accuracy: 0.3455 - val_loss: 1.9709 - val_accuracy: 0.2600\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 1.7622 - accuracy: 0.3405 - val_loss: 1.9638 - val_accuracy: 0.2684\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 8s 719ms/step - loss: 1.7461 - accuracy: 0.3445 - val_loss: 1.9667 - val_accuracy: 0.2578\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 7s 618ms/step - loss: 1.7473 - accuracy: 0.3395 - val_loss: 1.9656 - val_accuracy: 0.2569\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 7s 620ms/step - loss: 1.7354 - accuracy: 0.3415 - val_loss: 1.9699 - val_accuracy: 0.2529\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 7s 615ms/step - loss: 1.7433 - accuracy: 0.3465 - val_loss: 1.9619 - val_accuracy: 0.2649\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 7s 630ms/step - loss: 1.7442 - accuracy: 0.3485 - val_loss: 2.0044 - val_accuracy: 0.2524\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 7s 625ms/step - loss: 1.7384 - accuracy: 0.3460 - val_loss: 2.0040 - val_accuracy: 0.2511\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 7s 613ms/step - loss: 1.7395 - accuracy: 0.3615 - val_loss: 1.9866 - val_accuracy: 0.2573\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 7s 623ms/step - loss: 1.7473 - accuracy: 0.3460 - val_loss: 1.9863 - val_accuracy: 0.2476\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 7s 621ms/step - loss: 1.7471 - accuracy: 0.3475 - val_loss: 1.9695 - val_accuracy: 0.2591\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 7s 615ms/step - loss: 1.7378 - accuracy: 0.3490 - val_loss: 1.9702 - val_accuracy: 0.2529\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 7s 618ms/step - loss: 1.7311 - accuracy: 0.3435 - val_loss: 1.9665 - val_accuracy: 0.2622\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 1.7183 - accuracy: 0.3575 - val_loss: 1.9667 - val_accuracy: 0.2578\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 7s 613ms/step - loss: 1.7024 - accuracy: 0.3720 - val_loss: 1.9547 - val_accuracy: 0.2671\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 7s 614ms/step - loss: 1.7013 - accuracy: 0.3675 - val_loss: 1.9566 - val_accuracy: 0.2560\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 1.7131 - accuracy: 0.3580 - val_loss: 1.9606 - val_accuracy: 0.2653\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 7s 612ms/step - loss: 1.7120 - accuracy: 0.3685 - val_loss: 1.9768 - val_accuracy: 0.2613\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 7s 626ms/step - loss: 1.6953 - accuracy: 0.3700 - val_loss: 1.9715 - val_accuracy: 0.2662\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 7s 615ms/step - loss: 1.6858 - accuracy: 0.3680 - val_loss: 1.9672 - val_accuracy: 0.2653\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 7s 622ms/step - loss: 1.6985 - accuracy: 0.3565 - val_loss: 1.9683 - val_accuracy: 0.2533\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 7s 611ms/step - loss: 1.6991 - accuracy: 0.3600 - val_loss: 1.9728 - val_accuracy: 0.2489\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 7s 625ms/step - loss: 1.6984 - accuracy: 0.3820 - val_loss: 1.9634 - val_accuracy: 0.2533\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 7s 616ms/step - loss: 1.6855 - accuracy: 0.3725 - val_loss: 1.9424 - val_accuracy: 0.2689\n",
            "Epoch 49/100\n",
            "10/11 [==========================>...] - ETA: 0s - loss: 1.6949 - accuracy: 0.3693"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-1e53ec0c5734>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m history = model.fit(\n\u001b[0;32m----> 9\u001b[0;31m     train_data, train_label, epochs=100, batch_size=batch_size, validation_data=(test_data, test_label))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2454\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2456\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1861\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    503\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}